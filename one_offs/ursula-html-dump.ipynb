{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://ci_ro_infosec-dcu:****@artifactory.secureserver.net/artifactory/api/pypi/python-virt/simple\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.7/site-packages (3.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/nwade/src/github.com/gdcorp-infosec/dcu-scripts/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import gridfs\n",
    "\n",
    "mongo_client = MongoClient('')\n",
    "db = mongo_client['phishstory']\n",
    "collection = db['incidents']\n",
    "grid = gridfs.GridFS(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping sources\n",
      "Done mapping sources\n",
      "Done building new CSV\n",
      "Done saving all data files\n"
     ]
    }
   ],
   "source": [
    "import bson\n",
    "tickets = collection.find(\n",
    "    {'type': 'PHISHING', 'phishstory_status': 'CLOSED', 'ursula_classification': {'$exists': True}, 'initial_sourcecode_id': {'$exists': True}},\n",
    "    {'initial_sourcecode_id': 1, 'source': 1}\n",
    ")\n",
    "source_id_map = {}\n",
    "print('Mapping sources')\n",
    "for ticket in tickets:\n",
    "    source_id_map[ticket['source']] = ticket['initial_sourcecode_id']\n",
    "print('Done mapping sources')\n",
    "\n",
    "with open('ursula-dump-gocentral.csv', 'r') as in_file:\n",
    "    with open('dump-with-html.csv', 'w') as out:\n",
    "        headers = in_file.readline().strip()\n",
    "        out.write(f'{headers},file path')\n",
    "        for line in in_file:\n",
    "            fields = line.strip().split(',')\n",
    "            status = fields[0]\n",
    "            source = fields[1]\n",
    "            ursula_classification = fields[2]\n",
    "            ursula_score = fields[3]\n",
    "            if status == 'false_positive' or ursula_classification == 'Phishing' or ursula_classification == 'NotPhishing':\n",
    "                if source_id_map.get(source):\n",
    "                    fields.append(f'data/{source_id_map[source]}.html')\n",
    "                    out.write(','.join(fields) + '\\n')\n",
    "                else:\n",
    "                    fields.append(f'no data')\n",
    "                    out.write(','.join(fields) + '\\n')\n",
    "print('Done building new CSV')\n",
    "with open('dump-with-html.csv', 'r') as out:\n",
    "    headers = out.readline().strip()\n",
    "    for line in out:\n",
    "        fields = line.strip().split(',')\n",
    "        status = fields[0]\n",
    "        source = fields[1]\n",
    "        ursula_classification = fields[2]\n",
    "        ursula_score = fields[3]\n",
    "        data = fields[4]\n",
    "        if data != 'no data':\n",
    "            with open(data, 'w') as data_file:\n",
    "                file_id = data.split('data/')[1].split('.html')[0]\n",
    "                try:\n",
    "                    with grid.get(file_id) as fs_read:\n",
    "                        data_file.write(fs_read.read().decode('utf-8'))\n",
    "                except gridfs.NoFile as e:\n",
    "                    data_file.write('')\n",
    "                \n",
    "print('Done saving all data files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, getsize\n",
    "\n",
    "with open('dump-with-html.csv', 'r') as in_file:\n",
    "    with open('updated-with-html.csv', 'w') as out:\n",
    "        headers = in_file.readline().strip()\n",
    "        for line in in_file:\n",
    "            fields = line.strip().split(',')\n",
    "            status = fields[0]\n",
    "            source = fields[1]\n",
    "            ursula_classification = fields[2]\n",
    "            ursula_score = fields[3]\n",
    "            data = fields[4]\n",
    "            if exists(data) and getsize(data) > 0:\n",
    "                fields[4] = f'data/{source_id_map[source]}.html'\n",
    "                out.write(','.join(fields) + '\\n')\n",
    "            else:\n",
    "                fields[4] = f'no data'\n",
    "                out.write(','.join(fields) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0a12ebce89aca5fc19b8721555c6ed224d92a9ef606043d9130b199e4a4ef45"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
